%Erstellt mit WinEdt 6
\documentclass{beamer} %%% F\"{U}R VORTRAG MIT PAUSEN
%\documentclass[handout]{beamer} %%% F\"{U}R HANDOUT ALS PDF

\setbeamertemplate{navigation symbols}{}
\usetheme{Madrid}
\usecolortheme{seagull}
\beamersetuncovermixins{\opaqueness<1>{25}}{\opaqueness<2->{15}}
\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[babel,german=quotes]{csquotes} %im deutschen \"{u}bliche Anf\"{u}hrungszeichen
\usepackage{verbatim}
\newcounter{saveenumi}
\newcommand{\seti}{\setcounter{saveenumi}{\value{enumi}}}
\newcommand{\conti}{\setcounter{enumi}{\value{saveenumi}}}


\begin{document}
\author[Willi Mutschler]{Dr. Andrea Beccarini $\qquad$ Willi Mutschler, M.Sc.}
\date{Sommersemester 2012}
\institute[Institut f\"{u}r \"{O}konometrie]{Institut f\"{u}r \"{O}konometrie und
Wirtschaftsstatistik M\"{u}nster\\willi.mutschler@uni-muenster.de}
\title{DSGE-Modelle}
\subtitle{Verfahren vollst\"{a}ndiger Information\\Kalman-Filter, Maximum Likelihood und Bayesianische Methoden}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}\frametitle{Verfahren vollst\"{a}ndiger Information}
\tableofcontents
\end{frame}

\section{Idee}

\begin{frame}\frametitle{Verfahren vollst\"{a}ndiger Information}\framesubtitle{Idee}
    \begin{itemize}
      \item Verfahren vollst\"{a}ndiger Information bauen auf einer kompletten Charakterisierung des Daten generierenden Prozesses auf (keine Beschr\"{a}nkung auf bestimmte Momente).
      \item Betrachte die lineare \emph{state-space} Repr\"{a}sentation des Modells:
        \begin{align}
        \mathbf{x_t} &= \mathbf{F}(\boldsymbol{\mu}) \mathbf{x_{t-1}} + \mathbf{G}(\boldsymbol{\mu}) \boldsymbol{\upsilon_{t}},  &\text{mit }&E[\boldsymbol{\upsilon_t} \boldsymbol{\upsilon_t}']=\mathbf{V},\quad E[\boldsymbol{\upsilon_t} \boldsymbol{\upsilon_s}']=0 \label{transition}\\
        \mathbf{X_t} &= \mathbf{H}(\boldsymbol{\mu})' \mathbf{x_t }+ \mathbf{e_t},& \text{mit }& E[\mathbf{e_t} \mathbf{e_t}']= \boldsymbol{\Sigma_e}, \quad E[\mathbf{e_t} \mathbf{e_s}']=0 \label{observer}
        \end{align}
    \item Matrix $\mathbf{H}$ verkn\"{u}pft die Variablen des Modells $\mathbf{x_t}$ mit den beobachtbaren Daten $\mathbf{X_t}$ .
    \item Gleichung \eqref{transition}: \emph{state-} oder \emph{transition-equation}
    \begin{itemize}
      \item Entspricht der L\"{o}sung des Modells.
      \item $\boldsymbol{\upsilon_t}$ sind die stochastischen Innovationen.
    \end{itemize}
    \item Gleichung \eqref{observer}: \emph{observation-equation}
    \begin{itemize}
      \item Entspricht den Messgleichungen,
      \item unter Ber√ºcksichtigung eventueller Messfehler $\mathbf{e_t}$ in den Daten.
    \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}\frametitle{Verfahren vollst\"{a}ndiger Information}\framesubtitle{Idee}
  \begin{itemize}
    \item Trifft man nun Annahmen \"{u}ber die Verteilung von $\boldsymbol{\upsilon_t}$ und $\mathbf{e_t}$, so l\"{a}sst sich die Log-Likelihood-Funktion, $\log{L(\mathbf{X}|\boldsymbol{\mu})}$, analytisch bzw. numerisch herleiten.
    \item Im linearen Fall und unter der Annahme normalverteilter Variablen, kann die Likelihood mithilfe des Kalman-Filters berechnet werden.
    \item Im nichtlinearen Fall betrachtet man $\mathbf{s_t}=s(\mathbf{s_{t-1}},\boldsymbol{\upsilon_t}), \mathbf{c_t} = c(\mathbf{s_t})$ und $\mathbf{X_t} =\widetilde{h}(\mathbf{s_t},\mathbf{c_t},\boldsymbol{\upsilon_t}, \mathbf{e_t})\equiv h(\mathbf{s_t},\mathbf{e_t})$, wobei $c$,$s$ und $h$ Funktionen des Parametervektors $\boldsymbol{\mu}$ sind. F\"{u}r die Herleitung der Likelihood wird dann der Partikelfilter oder das \emph{efficient importance sampling} verwendet.
    \item Bei der Analyse und Auswertung der Log-Likelihood lassen sich zwei Herangehensweisen unterscheiden:
    \begin{enumerate}
      \item \textbf{die klassische, frequentistische \emph{Maximum-Likelihood}-Methode},
      \item \textbf{die bayesianische Methode}.
    \end{enumerate}
  \end{itemize}
\end{frame}

\section{Kalman-Filter}
\begin{frame}\frametitle{Verfahren vollst\"{a}ndiger Information}
  \tableofcontents[currentsection]
\end{frame}
\subsection{Notation}
\begin{frame}\frametitle{Kalman-Filter}\framesubtitle{Notation}
Wir beschr\"{a}nken uns auf den linearen Fall und ignorieren, vereinfachend, eventuelle Messfehler in den Daten:
\begin{itemize}
    \item $\mathbf{X_t} = \mathbf{H}'\mathbf{x_t}$
    \item $    \mathbf{x_{t+1}} = \mathbf{F} \mathbf{x_t} + \mathbf{G}\boldsymbol{\upsilon_{t+1}}$
    \item $\boldsymbol{\upsilon_{i}} \overset{iid}{\sim} \mathcal{N}(\mathbf{0},\mathbf{V}),~ \mathbf{V} = E(\boldsymbol{\upsilon_{i}} \boldsymbol{\upsilon_{i}}'), ~ E(\boldsymbol{\upsilon_{i}} \boldsymbol{\upsilon_{j}}')=0$
  \end{itemize}
\scriptsize
\begin{block}{Notation f\"{u}r die lineare Projektion}
\begin{align*}
\mathbf{\widehat{x}_{t|t-j}} &= E(\mathbf{x_t}|\mathbf{X_{t-j}},\mathbf{X_{t-j-1}},\dots \mathbf{X_{1}})\\
\boldsymbol{\Sigma_{t|t-j}} &= E(\mathbf{x_t}-\mathbf{\widehat{x}_{t|t-j}})(\mathbf{x_t}-\mathbf{\widehat{x}_{t|t-j}})'\\
\mathbf{\widehat{X}_{t|t-j}} &= E(\mathbf{X_t|X_{t-j}},\mathbf{X_{t-j-1}},\dots,\mathbf{X_1})\\
\mathbf{u_t} &= \mathbf{X_t} - \mathbf{\widehat{X}_{t|t-1}} = \mathbf{H'} (\mathbf{x_t} - \mathbf{\widehat{x}_{t|t-1}})\\
E(\mathbf{u_t}\mathbf{u_t}')&= \mathbf{H'} \boldsymbol{\Sigma_{t|t-1}} \mathbf{H}
\end{align*}
f\"{u}r $t=1,2,\dots,T$ und $j=0,1,\dots T$.
\end{block}

\end{frame}

\subsection{Initialisierung}
\begin{frame}\frametitle{Kalman-Filter}\framesubtitle{Initialisierung}
  \begin{itemize}
    \item Da $\mathbf{x_t}$ schwach-station\"{a}r
ist, gilt f\"{u}r die Varianz:
\begin{align*}
    \underbrace{E(\mathbf{x_t} \mathbf{x_t}')}_{\equiv \boldsymbol{\Sigma}}&=E\left[(\mathbf{F} \mathbf{x_{t-1}} + \mathbf{G} \boldsymbol{\upsilon_t})(\mathbf{F} \mathbf{x_{t-1}} + \mathbf{G} \boldsymbol{\upsilon_t})'\right] \\
    &= \mathbf{F} \underbrace{E(\mathbf{x_{t-1}}\mathbf{x_{t-1}}')}_{\equiv \boldsymbol{\Sigma}}\mathbf{F}' + \mathbf{G} \underbrace{E(\boldsymbol{\upsilon_t} \boldsymbol{\upsilon_t}')}_{=\mathbf{V}} \mathbf{G}'\\
\Leftrightarrow \boldsymbol{\Sigma} &= \mathbf{F} \boldsymbol{\Sigma} \mathbf{F'} + \mathbf{G} \mathbf{V} \mathbf{G}'\\
\end{align*}
\item \begin{block}{Vektorisierung}
    $vec$-Operator stapelt die Spalten einer $m\times n$ Matrix $\mathbf{M}$ in einem $mn\times 1$ Vektor $vec(\mathbf{M})$. Dann gilt f\"{u}r beliebige Matrizen $\underset{m\times n}{A}$,$\underset{n\times p}{B}$ und $\underset{p \times k}{C}$:
    \begin{align*}
        vec(ABC) = (C' \otimes A)vec(B), \quad \text{wobei } \otimes: \text{Kroneckerprodukt.}
    \end{align*}
\end{block}
  \end{itemize}
\end{frame}

\begin{frame}\frametitle{Kalman-Filter}\framesubtitle{Initialisierung}
  \begin{itemize}
        \item Angewandt ergibt sich somit folgende L\"{o}sung f\"{u}r $\boldsymbol{\Sigma}$:
\begin{align*}
    vec(\boldsymbol{\Sigma}) &= (\mathbf{F} \otimes \mathbf{F} ) vec(\boldsymbol{\Sigma}) + vec(\mathbf{G} \mathbf{V} \mathbf{G}')\\
\Leftrightarrow    vec(\boldsymbol{\Sigma}) &= (\mathbf{I}-\mathbf{F} \otimes \mathbf{F})^{-1} vec(\mathbf{G} \mathbf{V} \mathbf{G}')
\end{align*}
\item Die Initialisierung des Kalman-Filters erfolgt mit dem unbedingten Erwartungswert von $\mathbf{x_1}$, da noch keine Beobachtungen zur Verf\"{u}gung
stehen:
\begin{align*}
\mathbf{\widehat{x}_1} &= \underbrace{E(\mathbf{x_1})}_{=E(\mathbf{x})} = \mathbf{F }\underbrace{E(\mathbf{x_0})}_{=E(\mathbf{x})} + \mathbf{G}\underbrace{E(\boldsymbol{\upsilon_1})}_{=0} \Leftrightarrow \mathbf{\widehat{x}_1} = \mathbf{0},\\
vec(\boldsymbol{\Sigma_{1|0}}) & = E(\mathbf{x_1}-\textbf{0})(\mathbf{x_1}-\textbf{0})'=(\mathbf{I}-\mathbf{F} \otimes \mathbf{F})^{-1} vec(\mathbf{G} \mathbf{V} \mathbf{G}').
\end{align*}

  \end{itemize}
\end{frame}

\subsection{Rekursion}
\begin{frame}\frametitle{Kalman-Filter}\framesubtitle{Rekursion}
Die weiteren Rekursionsschritte orientieren sich an:
\begin{align*} \mathbf{\widehat{x}_{t+1|t}} = \mathbf{F} \mathbf{\widehat{x}_{t|t}} \end{align*}
\begin{block}{\scriptsize Formel f\"{u}r die Aktualisierung einer linearen Projektion (Hamilton (1994,~S.99 und S.379))}
\scriptsize\begin{align*}
  \mathbf{\widehat{x}_{t|t}} &= \mathbf{\widehat{x}_{t|t-1}}  +\left[E(\mathbf{x_t}-\mathbf{\widehat{x}_{t|t-1}})(\mathbf{X_t}-\mathbf{\widehat{X}_{t|t-1}})'\right] \left[E(\mathbf{X_t}-\mathbf{\widehat{X}_{t|t-1}})(\mathbf{X_t}-\mathbf{\widehat{X}_{t|t-1}})'\right]^{-1} \mathbf{u_t}\\
 \Leftrightarrow \mathbf{\widehat{x}_{t|t}}&= \mathbf{\widehat{x}_{t|t-1}}+ \boldsymbol{\Sigma_{t|t-1}} \mathbf{H} \left(\mathbf{H}'\boldsymbol{\Sigma_{t|t-1}}\mathbf{H}\right)^{-1} \mathbf{u_t}\\
  \Rightarrow \mathbf{\widehat{x}_{t+1|t}} = \mathbf{F} \mathbf{\widehat{x}_{t|t}} &=\mathbf{F} \mathbf{\widehat{x}_{t|t-1}}+ \mathbf{F}\boldsymbol{\Sigma_{t|t-1}} \mathbf{H} \left(\mathbf{H}'\boldsymbol{\Sigma_{t|t-1}}\mathbf{H}\right)^{-1} \mathbf{u_t}, \\
  &\qquad\qquad\qquad\qquad\qquad\qquad\qquad~~~ \text{mit } \mathbf{u_t} = \mathbf{X_t} - \mathbf{\widehat{X}_{t|t-1}} = \mathbf{H'} (\mathbf{x_t} - \mathbf{\widehat{x}_{t|t-1}}).
\end{align*}
\end{block}
\end{frame}

\begin{frame}\frametitle{Kalman-Filter}\framesubtitle{Rekursion}
\begin{itemize}
\item $\mathbf{x_{t+1}} - \mathbf{\widehat{x}_{t+1|t}} = \mathbf{F}\left(\mathbf{x_{t}} - \mathbf{\widehat{x}_{t|t-1}}\right) + \mathbf{G} \boldsymbol{\upsilon_{t+1}} - \mathbf{F}\boldsymbol{\Sigma_{t|t-1}} \mathbf{H} \left(\mathbf{H}'\boldsymbol{\Sigma_{t|t-1}}\mathbf{H}\right)^{-1} \mathbf{u_t}$
\item Der \emph{MSE: } $\boldsymbol{\Sigma_{t+1|t} }= E\left(\mathbf{x_{t+1}} - \mathbf{\widehat{x}_{t+1|t}}\right)\left(\mathbf{x_{t+1}} - \mathbf{\widehat{x}_{t+1|t}}\right)'$ ist dann gegeben durch:
\scriptsize\begin{align*}
    &\boldsymbol{\Sigma_{t+1|t} }=\\
    & \mathbf{F} \boldsymbol{\Sigma_{t|t-1}} \mathbf{F'} + \mathbf{G} \mathbf{V} \mathbf{G}' - \mathbf{F}\boldsymbol{\Sigma_{t|t-1}} \mathbf{H} \underbrace{\left(\mathbf{H}'\boldsymbol{\Sigma_{t|t-1}}\mathbf{H}\right)^{-1} \underbrace{E(\mathbf{u_t} \mathbf{u_t'})}_{=\mathbf{H'} \boldsymbol{\Sigma_{t|t-1}} \mathbf{H}}}_{=\mathbf{I}}
    \left(\mathbf{H}'\boldsymbol{\Sigma_{t|t-1}}\mathbf{H}\right)^{-1} \mathbf{H}' \boldsymbol{\Sigma_{t|t-1}} \mathbf{F}'
\end{align*}
\end{itemize}
\scriptsize\begin{block}{Mean-Sqared-Error (MSE)}\centering
$
\boldsymbol{\Sigma_{t+1} } \equiv \boldsymbol{\Sigma_{t+1|t} }      = \mathbf{F} \boldsymbol{\Sigma_{t|t-1}} \mathbf{F'} + \mathbf{G} \mathbf{V} \mathbf{G}' - \mathbf{F}\boldsymbol{\Sigma_{t|t-1}} \mathbf{H} \left(\mathbf{H}'\boldsymbol{\Sigma_{t|t-1}}\mathbf{H}\right)^{-1} \mathbf{H}' \boldsymbol{\Sigma_{t|t-1}}\mathbf{F}'
$
\end{block}
\end{frame}

\subsection{Zusammenfassung und Likelihood}
\begin{frame}\frametitle{Kalman-Filter}\framesubtitle{Zusammenfassung}
Bezeichne:
\begin{itemize}
\item $\mathbf{K_t}=\mathbf{F}\boldsymbol{\Sigma_{t}} \mathbf{H} \left(\mathbf{H}'\boldsymbol{\Sigma_{t}}\mathbf{H}\right)^{-1}$ die
sogenannte \emph{Gain-Matrix},
\item $\mathbf{\widehat{x}_t}=\mathbf{\widehat{x}_{t|t-1}}$ die lineare Projektion,
\item wobei $\boldsymbol{\Sigma_t}=\boldsymbol{\Sigma_{t|t-1}}$ der zugeh\"{o}rige \emph{Mean Squared Error} ist.
\end{itemize}
Dann l\"{a}sst sich der Kalman-Filter folgenderma{\ss}en zusammenfassen:
\begin{enumerate}
  \item Initialisierung mit
  \begin{itemize}
  \item $\mathbf{\widehat{x}_1} = \mathbf{0}$,
  \item $vec(\boldsymbol{\Sigma_{1|0}}) = (\mathbf{I}-\mathbf{F}
      \otimes \mathbf{F})^{-1} vec(\mathbf{G} \mathbf{V}
      \mathbf{G}')$.
  \end{itemize}
  \item Rekursion mit
   \begin{itemize}
   \item $\mathbf{u_t} = \mathbf{X_t} -\mathbf{\widehat{X}_t}
       =\mathbf{X_t} - \mathbf{H}' \mathbf{\widehat{x}_t}$,~~~
       $E(\mathbf{u_t}
       \mathbf{u_t'})=\mathbf{H}'\boldsymbol{\Sigma_t}
       \mathbf{H}\equiv \boldsymbol{\Omega_t}$,
    \item $\mathbf{\widehat{x}_{t+1}}=\mathbf{F}
        \mathbf{\widehat{x}_{t}} + \mathbf{K_t} \mathbf{u_t}$,
    \item $\boldsymbol{\Sigma_{t+1}} = \mathbf{F}
        \boldsymbol{\Sigma_{t}} \mathbf{F'} + \mathbf{G} \mathbf{V}
        \mathbf{G}' - \mathbf{K_t} \mathbf{H}'
        \boldsymbol{\Sigma_{t}}\mathbf{F}'$.
    \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}\frametitle{Log-Likelihood}
  Mithilfe der Normalverteilungsannahme des Prognosefehlers $\mathbf{u_t}$ l\"{a}sst sich nun die Verteilung der Daten $\underset{n \times 1}{\mathbf{X_t}}$ bedingt auf
$(\mathbf{x_t},\mathbf{X_{t-1}},\mathbf{X_{t-2}},\dots)$ bestimmen und die Log-Likelihood Funktion aufstellen:

\begin{block}{Log-Likelihood}
\begin{align*}
\log{ \mathcal{L}(\mathbf{X}|\boldsymbol{\mu})} &= \sum_{t=1}^T \log{\mathcal{L}(\mathbf{X_t}|\boldsymbol{\mu})}\\ &=-\frac{nT}{2} \log(2\pi) - \frac{1}{2}\sum_{t=1}^{T} \log{|\boldsymbol{\Omega_t}|}- \frac{1}{2} \sum_{t=1}^T \mathbf{u_t}' \boldsymbol{\Omega_t}^{-1} \mathbf{u_t}.
\end{align*}
\end{block}
\end{frame}

\section{Maximum-Likelihood}
\begin{frame}\frametitle{Verfahren vollst\"{a}ndiger Information}
  \tableofcontents[currentsection]
\end{frame}
\subsection{Idee}
\begin{frame}\frametitle{Maximum-Likelihood}\framesubtitle{Idee}
  \begin{itemize}
    \item \textbf{Betrachtungsweise:} Parametervektor $\boldsymbol{\mu}$ ist fix und die Daten sind eine zuf\"{a}llige Realisation unter
vielen.
    \item  Der \emph{Maximum-Likelihood}-Sch\"{a}tzer $\boldsymbol{\widehat{\mu}_{ML}}$ ist dann definiert als
    \begin{align*}
    \boldsymbol{\widehat{\mu}_{ML}} = \underset{\mu}{\text{argmax}}\left\{ \sum_{t=1}^T \log{\mathcal{L}(\mathbf{X_t}|\boldsymbol{\mu})} \right\}.
    \end{align*}
    \item Unter geeigneten Regularit\"{a}tsbedingungen ist der \emph{ML}-Sch\"{a}tzer konsistent, asymptotisch effizient und asymptotisch normalverteilt.
    \item Die Unsicherheit bzw. M\"{o}glichkeit der Inferenz beruht auf der Annahme, dass zu \textbf{jeder anderen Realisation der Daten ein etwas anderer Parametervektor geh\"{o}rt, der die Likelihood maximiert}.
    \item Hinweis f\"{u}r die Sch\"{a}tzung der Parameter eines DSGE-Modells:
    \begin{itemize} \item Die Dimension von $\mathbf{X_t}$ muss mindestens so gro{\ss} sein, wie die Dimension der strukturellen Schocks $\boldsymbol{\upsilon_t}$, da es sonst zu einer singul\"{a}ren Varianz-Kovarianz-Matrix des Residualterms f\"{u}hrt.
    \item Falls nicht: entweder Messfehler oder weitere Schocks hinzuf\"{u}gen.
  \end{itemize}
  \end{itemize}
\end{frame}

\subsection{Aufgabe 4: An und Schorfheide (2007) mit Maximum-Likelihood}
\begin{frame}\frametitle{Aufgabe 4: An und Schorfheide (2007) mit ML}
Betrachten Sie folgendes linearisierte neukeynesianische Modell:
    \begin{align*}
  \widehat{y}_t &= E_t[\widehat{y}_{t+1}] + \widehat{g}_t - E_t[\widehat{g}_{t+1}] - \frac{1}{\tau} (\widehat{R}_t - E_t[\widehat{\pi}_{t+1}] - E_t[\widehat{z}_{t+1}]),\\
  \widehat{\pi}_t &= \beta E_t[\widehat{\pi}_{t+1}]+\kappa(\widehat{y}_t-\widehat{g}_t),\\
    \widehat{c_t} &= \widehat{y_t }- \widehat{g_t},\\
  \widehat{R}_{t} &= \rho_R \widehat{R}_{t-1} + (1-\rho_R)\psi_1 \widehat{\pi}_{t} + (1-\rho_R)\psi_2 \left(\widehat{y}_{t}-\widehat{g}_{t}\right) + \epsilon_{R,t}\\
 \widehat{g}_{t} &= \rho_g \widehat{g}_{t-1} + \epsilon_{g,{t}},\\
 \widehat{z}_{t} &= \rho_z \widehat{z}_{t-1} + \epsilon_{z,{t}},
\end{align*}
wobei alle Variablen mit $\widehat{~}$, die logarithmierte Abweichungen vom steady-state bezeichnen, d.h. $\widehat{x_t}=log(x_t)-log(x)$. \\Die stochastischen Schocks sind normalverteilt mit $E[\epsilon_{i,t}]=0$ und $E[\epsilon_{i,t}^2]=\sigma_i^2$.
\end{frame}

\begin{frame}\frametitle{Aufgabe 4: An und Schorfheide (2007) mit ML}
\begin{itemize}
\item Ihnen liegen Daten auf Quartalsebene zu folgenden Gr√∂√üen vor:
\begin{itemize}
  \item Quartalswachstumsraten des pro-Kopf BIPs in Prozent $(YGR_t)$,
  \item Annualisierte Inflationsraten in Prozent $(INFL_t)$,
  \item Annualisierte Nominalzinss√§tze in Prozent $(INT_t)$.
\end{itemize}
\item Modellvariablen und beobachtbare Daten sind folgenderma√üen miteinander verkn√ºpft:
\begin{align*}
  YGR_t &= \gamma^{(Q)} + 100(\widehat{y}_t-\widehat{y}_{t-1}+\widehat{z}_t),\\
  INFL_t &= \pi^{(A)} + 400 \widehat{\pi}_t,\\
  INT_t &= \pi^{(A)} + r^{(A)} + 4 \gamma^{(Q)} + 400 \widehat{R}_t.
\end{align*}
\item Die Parameter $\gamma^{(Q)}, \pi^{(A)}$ und $r^{(A)}$ haben folgende
Beziehung zu den \emph{steady-state} Werten:
\scriptsize\begin{align*}
  \gamma &=\frac{A_{t+1}}{A_t}= e^{\frac{\gamma_Q}{100}} \approx 1+\frac{\gamma^{(Q)}}{100}, \qquad   \pi = e^{\frac{\pi^{(A)}}{400}} \approx 1+\frac{\pi^{(A)}}{400},\qquad r = e^{\frac{r^{(A)}}{400}} \approx 1+\frac{r^{(A)}}{400},\\
  \beta&=e^{-\frac{r^{(A)}}{400}} \approx \frac{1}{1+r^{(A)}/400}.
\end{align*}
\end{itemize}
\end{frame}

\begin{frame}\frametitle{Aufgabe 4: An und Schorfheide (2007) mit ML}
Erstellen Sie eine mod-Datei f√ºr das Modell, mit der Sie die Parameter mithilfe der Maximum-Likelihood-Methode sch√§tzen k√∂nnen.
  \begin{enumerate}[(a)]
    \item Verwenden Sie zur Sch√§tzung den simulierten Datensatz \texttt{simdat1.mat}. Dabei wurden folgende Parameter verwendet:
   \begin{align*}
          \tau&=2.000,&	\kappa&=0.150, &\psi_1 &=1.500,	&\psi_2=1.000,\\
          \rho_R&=0.600,	&\rho_z &=0.650,& \rho_g&=0.950, \\
          \sigma_R&=0.2/100, &\sigma_g&=0.8/100 ,&	\sigma_z&=0.45/100 ,\\
           \pi^{(A)}&=4.000, &\gamma^{(Q)}&=0.500, &r^{(A)}&=0.400.
    \end{align*}
    \begin{enumerate}
    \item Sch√§tzen Sie alle Parameter mit ML. Warum gelingt dies nicht? Hinweis: Das nichtlineare Modell impliziert, dass $\beta=\frac{\gamma}{r}=\frac{e^{\frac{\gamma^{(Q)}}{100}}}{e^{\frac{r^{(A)}}{400}}}$.
    \item Kalibrieren Sie nun die Parameter $\psi_1$ und $r^{(A)}$ auf ihren wahren Wert und sch√§tzen Sie die restlichen Parameter. Warum gelingt dies nun?
  \end{enumerate}\seti
  \end{enumerate}
\end{frame}

\begin{frame}\frametitle{Aufgabe 4: An und Schorfheide (2007) mit ML}
    \begin{enumerate}[(a)]\conti
    \item Verwenden Sie zur Sch√§tzung nun den simulierten Datensatz \texttt{simdat2.mat}. Bei diesem Datensatz wurde $r^{(A)}=4$ verwendet.
    \begin{enumerate}
      \item Sch√§tzen Sie alle Parameter mit ML. Warum gelingt dies immer noch nicht?
      \item Kalibrieren Sie nun den Parameter $\psi_1$ auf seinen wahren Wert und sch√§tzen Sie die restlichen Parameter. Beurteilen Sie ihr Ergebnis.
    \end{enumerate}
    \end{enumerate}
\end{frame}

\section{Bayesianische Sch\"{a}tzung}
\begin{frame}\frametitle{Verfahren vollst\"{a}ndiger Information}
  \tableofcontents[currentsection]
\end{frame}

\subsection{Idee}
\begin{frame}\frametitle{Bayesianische Sch\"{a}tzung}\framesubtitle{Idee}
\begin{itemize}
  \item Die Erfahrung zeigt, dass es ziemlich schwer sein kann ein DSGE-Modell mit Maximum-Likelihood zu sch√§tzen.
  \item Daten sind oft nicht ausreichend informativ, d.h. die Likelihood ist flach in einigen Richtungen (Identfizierung).
  \item DSGE-Modell sind an sich misspezifiziert. Dies kann zu absurden Parameterwerten f√ºhren.
\end{itemize}
\end{frame}

\begin{frame}\frametitle{Bayesianische Sch\"{a}tzung}\framesubtitle{Idee}
\begin{itemize}
  \item Basiert auch auf der Likelihood: der kompletten Charakterisierung des Daten generierenden Prozesses.
  \item \textbf{Betrachtungsweise:} Parametervektor $\boldsymbol{\mu}$ ist eine Zufallsvariable und die Daten $\mathbf{X}$ sind fix.
  \item Die Idee ist, bekannte Informationen (die Daten) mit zus\"{a}tzlichen Auffassungen (\emph{prior-believes}) \"{u}ber die Parameter zu kombinieren und Aussagen \"{u}ber die bedingte Wahrscheinlichkeitsverteilung der Parameter zu treffen.
  \item Bei der Sch\"{a}tzung kann so mehr Gewicht auf den vermuteten Bereich des Parameterraums gelegt werden.
  \item Bayesianische Methoden bilden somit eine Br\"{u}cke zwischen der Kalibrierung und dem \emph{Maximum-Likelihood}-Verfahren:
\end{itemize}
\textbf{\enquote{Bayesian Inference is a Way of Thinking, Not a Basket of Methods}}
\end{frame}

\begin{frame}\frametitle{Bayesianische Sch\"{a}tzung}\framesubtitle{Idee}
  \begin{itemize}
     \item Likelihood-Funktion $\mathcal{L}(\mathbf{X}|\boldsymbol{\mu})$ wird als auf die Parameter bedingte Dichte der beobachtbaren Daten interpretiert:
$\wp(\mathbf{X}|\boldsymbol{\mu})=\mathcal{L}(\mathbf{X}|\boldsymbol{\mu})$.
     \item Bezeichne $\wp(\boldsymbol{\mu})$ die bekannte Priori-Dichtefunktion des Parametervektors, dann folgt nach der Regel von Bayes
\begin{align*}
    \wp(\boldsymbol{\mu}|\mathbf{X}) = \frac{\mathcal{L}(\mathbf{X}|\boldsymbol{\mu})\wp(\boldsymbol{\mu})}{\wp(\mathbf{X})} =  \frac{\mathcal{L}(\mathbf{X}|\boldsymbol{\mu})\wp(\boldsymbol{\mu})}{\int \wp(\boldsymbol{\mu}) \mathcal{L}(\mathbf{X|\boldsymbol{\mu}}) ~d\boldsymbol{\mu}} \propto \mathcal{L}(\mathbf{X}|\boldsymbol{\mu})\wp(\boldsymbol{\mu}),
\end{align*}
wobei $\propto$ \enquote{proportional zu} bedeutet.

     \item $\wp(\mathbf{X})$ ist die \emph{marginale Likelihood} der Daten
und letztlich nur eine Normierungskonstante, die nicht vom Parametervektor
abh\"{a}ngt. \item L\"{a}sst man diese weg, so bleibt die Gestalt der Posteriori-Dichte
$\wp(\boldsymbol{\mu}|\mathbf{X})$ erhalten, sie integriert sich lediglich
nicht zu eins. \item Diese nicht normalisierte Dichte wird auch
\emph{Posterior-Kernel} oder, logarithmiert, als \emph{Log-Posterior-Kernel}
bezeichnet.
   \end{itemize}
\end{frame}

\begin{frame}\frametitle{Bayesianische Sch\"{a}tzung}\framesubtitle{Idee}
  \begin{itemize}
    \item Der Modus ist dann der bayesianische Sch\"{a}tzer $\boldsymbol{\widehat{\mu}_B}$ f\"{u}r den wahren Parametervektor:
\begin{align*}
    \boldsymbol{\widehat{\mu}_B} = \underset{\mu}{\text{argmax}}\left\{\log{\wp(\boldsymbol{\mu}|\mathbf{X})}\right\} = \underset{\mu}{\text{argmax}}\left\{ \log{\mathcal{L}(\mathbf{X}|\boldsymbol{\mu})} + \log{\wp(\boldsymbol{\mu})} \right\}
\end{align*}
    \item Vorgehen: Log-Likelihood mithilfe des Kalman-Filters berechnen und \emph{Log-Posterior-Kernel} mit \emph{Sampling-} bzw. \emph{Monte-Carlo}-Methoden simulieren.
    \item  In der Literatur -- und in Dynare -- findet hierzu bevorzugt der \emph{Metropolis-Hastings-Algorithmus} Verwendung.
    \item  Inferenz l\"{a}sst sich dann mithilfe der Eigenschaften der Posteriori-Verteilung durchf\"{u}hren.
  \end{itemize}
\end{frame}

\subsection{Metropolis-Hastings-Algorithmus}
\begin{frame}\frametitle{Bayesianische Sch\"{a}tzung}\framesubtitle{Metropolis-Hastings-Algorithmus}
\begin{block}{An und Schorfheide (2007, S.~132)}
  The algorithm constructs a Gaussian approximation around the posterior mode and
  uses a scaled version of the asymptotic covariance matrix as the covariance
  matrix for the proposal distribution. This allows for an efficient
  exploration of the posterior distribution at least in the neighborhood of
  the mode.
\end{block}
\begin{itemize}
  \item Der Algorithmus nutzt aus, dass unter recht allgemeinen Bedingungen die Momente der Verteilung asymptotisch
normalverteilt sind.
\item Es wird eine Sequenz von Ziehungen, sogenannte Markov-Ketten, aus einer Vorschlagsdichte erstellt.
\item Diese braucht nicht identisch mit der Posteriori-Dichte zu sein, sondern gew\"{a}hrleistet, dass der Algorithmus
Stichproben aus der ganzen Breite der Posteriori-Dichte ziehen kann.
\end{itemize}
\end{frame}


\begin{frame}\frametitle{Bayesianische Sch\"{a}tzung}\framesubtitle{Metropolis-Hastings-Algorithmus}
\begin{itemize}
  \item Die aktuelle Ziehung $\boldsymbol{\mu^*}$ ist dabei abh\"{a}ngig von der vergangenen Ziehung $\boldsymbol{\mu^{(s-1)}}$.
  \item Alle Ziehungen werden zwar gleich gewichtet, allerdings nur mit einer bestimmten Wahrscheinlichkeit $\alpha$ auch akzeptiert. Diese wird dabei aus dem Quotient der \emph{Posterior-Kernel} des neuen und des aktuellen Kandidaten berechnet.
  \item Dieses Konstrukt erm\"{o}glicht es, dass der Algorithmus tendenziell die Ziehung von Bereichen geringer Posteriori-Wahrscheinlichkeit in Bereiche hoher Wahrscheinlichkeit verschiebt:
  \begin{itemize}
    \item Ist $\boldsymbol{\mu^{(s-1)}}$ in einem Bereich hoher Posteriori-Wahrscheinlichkeit, tendiert der Algorithmus dazu,
dort zu verweilen.
    \item Befindet sich $\boldsymbol{\mu^{(s-1)}}$ in einem Bereich niedriger Posteriori-Wahrscheinlichkeit, werden neue Kandidaten bevorzugt
akzeptiert.
  \end{itemize}
\item Die Wahl der Varianz-Kovarianz-Matrix der Vorschlagsdichte spielt hierbei eine entscheidende Rolle, damit $\alpha$ nicht zu gro{\ss}, aber auch
nicht zu klein gew\"{a}hlt wird.
\item Hier hat sich bew\"{a}hrt, die Varianz-Kovarianz-Matrix des Sch\"{a}tzers $\boldsymbol{\widehat{\mu}_B}$ zu verwenden und diese mit einem Faktor $c$ so zu skalieren, dass die durchschnittliche Akzeptanzwahrscheinlichkeit zwischen 20\% und 30\% liegt.
\end{itemize}

\end{frame}

\begin{frame}\frametitle{Bayesianische Sch\"{a}tzung}\framesubtitle{Metropolis-Hastings-Algorithmus}
\begin{enumerate}
\item Spezifiziere $c_0,c$ und $S$.
  \item Maximiere $\log{\mathcal{L}(\mathbf{X}|\boldsymbol{\mu})} +
      \log{\wp(\boldsymbol{\mu})}$ mithilfe numerischer Verfahren.\\
      $\boldsymbol{\widehat{\mu}_B}$ bezeichnet den Modus.
  \item Berechne die Inverse der Hessematrix ausgewertet am Modus,
      bezeichne diese mit $\boldsymbol{\Sigma_B}$.
  \item Spezifiziere einen Startwert $\boldsymbol{\mu^{(0)}}$ oder ziehe
      diesen aus
      $\mathcal{N}(\boldsymbol{\widehat{\mu}_B},c_0^2\boldsymbol{\Sigma_B})$.
\seti
\end{enumerate}

\end{frame}


\begin{frame}\frametitle{Bayesianische Sch\"{a}tzung}\framesubtitle{Metropolis-Hastings-Algorithmus}
\begin{enumerate}\conti
  \item F\"{u}r $\mathbf{s}=1,\dots,S$:
  \begin{itemize}
    \item Ziehe $\boldsymbol{\mu^*}$ aus der
        Kandidaten-generierenden-Verteilung
        $\mathcal{N}(\boldsymbol{\mu^{(s-1)}},c^2\boldsymbol{\Sigma_B})$.
    \item Berechne die Akzeptanz-Wahrscheinlichkeit $\alpha$:
        \begin{align*}
        \alpha \equiv \alpha\left(\boldsymbol{\mu^{(s-1)}},\boldsymbol{\mu^*}\right) = \frac{\mathcal{L}\left(\boldsymbol{\mu^{*}}|\mathbf{X}\right)~\wp\left(\boldsymbol{\mu^*}\right)}{\mathcal{L}\left(\boldsymbol{\mu^{(s-1)}}|\mathbf{X}\right)~\wp\left(\boldsymbol{\mu^{(s-1)}}\right)}
        \end{align*}
    \item Mit der Wahrscheinlichkeit
        $\text{min}\left\{\alpha,1\right\}$ wird der Sprung von
        $\boldsymbol{\mu^{(s-1)}}$ auf $\boldsymbol{\mu^*}$
        akzeptiert. D.h. falls $\alpha\geq1$, setze
        $\boldsymbol{\mu^{(s)}}=\boldsymbol{\mu^*}$.
    \item Mit der Gegenwahrscheinlichkeit wird der Sprung nicht
        akzeptiert. D.h. ziehe eine gleichverteilte Zufallsvariable $r$ zwischen $0$ und $1$:
        \begin{itemize}
        \item Falls $r\leq\alpha$ setze $\boldsymbol{\mu^{(s)}}=\boldsymbol{\mu^*}$.
        \item Falls $r>\alpha$ setze $\boldsymbol{\mu^{(s)}}=\boldsymbol{\mu^{(s-1)}}$.
         \end{itemize}
  \end{itemize}
\seti
\end{enumerate}

\end{frame}

\begin{frame}\frametitle{Bayesianische Sch\"{a}tzung}\framesubtitle{Metropolis-Hastings-Algorithmus}
\begin{enumerate}\conti
  \item Sch\"{a}tze den Posteriori-Erwartungswert einer Funktion
      $\hbar(\boldsymbol{\mu})$ mit $\frac{1}{S}\sum_{s=1}^S
      \hbar\left(\boldsymbol{\mu^{(s)}}\right)$.
  \item Falls die durchschnittliche Akzeptanzwahrscheinlichkeit nicht
      einen erw\"{u}nschten Wert hat (\"{u}blicherweise zwischen $20\%-30\%$) oder der Algorithmus nicht konvergiert,
\"{a}ndere $c_0,c$ oder $S$.
\end{enumerate}

\end{frame}

\subsection{Hinweise}
\begin{frame}\frametitle{Bayesianische Sch\"{a}tzung}\framesubtitle{Hinweise}
  \begin{itemize}
    \item Bayesianische Sch\"{a}tzung eines DSGE-Modells erfordert, dass die Anzahl der Schocks mit der Anzahl beobachtbarer Variablen
\"{u}bereinstimmt (nicht eindeutig identifizierbare Parameter).
    \item \"{U}bliche Priori-Verteilungen: Normalverteilung, (normale, verschobene oder inverse) Gammaverteilung, Betaverteilung oder Gleichverteilung.
    \item Bei der Wahl einer geeigneten Priori-Verteilung spielen \"{U}berlegungen zur unteren bzw. oberen Grenzen, sowie zur Schiefe und Kurtosis der Verteilung eine Rolle.
    \item Die Ergebnisse k√∂nnen stark abh√§ngen von der Wahl der Priori oder ihrer Parametrisierung.
    \item Deshalb muss die Robustheit der Resultate sicher gestellt werden:
    \begin{itemize}
      \item Unterschiedliche Parametrisierungen ausprobieren.
      \item Allgemeinere Priori-Verteilungen verwenden.
      \item Nichtinformative Priori-Verteilungen.
      \item Sensitivit√§tsanalysen.
    \end{itemize}
  \end{itemize}
\end{frame}

\subsection{Aufgabe 5: Sch\"{a}tzung mit Bayesianischen Methoden}

\begin{frame}\frametitle{Aufgabe 5: Sch\"{a}tzung mit Bayesianischen Methoden}
Betrachten Sie folgendes einfache RBC-Modell (soziale Planer-Problem);
\begin{align*}
  \underset{\{c_{t+j},l_{t+j},k_{t+j}\}_{j=0}^\infty}{max} W_t &= \sum_{j=0}^\infty \beta^j u(c_{t+j},l_{t+j})\\
  s.t.\quad y_t &= c_t + i_t, & A_t &= A e^{a_t}, \\
  y_t &= A_t f(k_{t-1},l_t), & a_t &= \rho a_{t-1} + \varepsilon_t,\\
  k_t &= i_t +(1-\delta)k_{t-1}, &  \varepsilon_t &\sim N(0,\sigma_{\varepsilon}^2),
\end{align*}
wobei f√ºr Pr√§ferenzen und Technologie folgendes gilt:
\begin{align*}
  u(c_t,l_t)= \frac{\left[c_t^\theta (1-l_t)^{1-\theta}\right]^{1-\tau}}{1-\tau}, \qquad f(k_{t-1},l_t)=\left[\alpha k_{t-1}^\psi + (1-\alpha)l_t^\psi\right]^{1/\psi}.
\end{align*}
Die Optimalit√§tsbedingungen sind gegeben durch:
\begin{eqnarray*}
 &u_c(c_t,l_t) - \beta E_t \left\{u_c(c_{t+1},l_{t+1}) \left[A_{t+1} f_k(k_t, l_{t+1})+1-\delta \right]\right\} = 0,\\
 & -\frac{u_l(c_t,l_t)}{u_c(c_t,l_t)}-A_t f_l(k_{t-1},l_t)=0,\\
 & c_t + k_t -A_t f(k_{t-1},l_t) -(1-\delta)k_{t-1}=0.
\end{eqnarray*}
\end{frame}

\begin{frame}\frametitle{Aufgabe 5: Sch\"{a}tzung mit Bayesianischen Methoden}
\begin{enumerate}[(a)]
  \item Schreiben Sie eine mod-Datei f√ºr dieses Modell (mit einer vern√ºnftigen Kalibrierung der Parameter und einem steady-state Block).
  \item Simulieren Sie einen Datensatz von 10000 Beobachtungen f√ºr $c_t,l_t$ und $y_t$ mit \texttt{stoch\_simul} und speichern Sie diesen in einer mat-Datei.
  \item Definieren Sie Priori-Verteilungen f√ºr $\alpha,\theta$ und $\tau$ (oder einer anderen Auswahl an Parametern).
  \item Sch√§tzen Sie den Posteriori-Modus (mithilfe des \texttt{estimation} Kommandos). Beschr√§nken Sie Ihren Datensatz auf 100 Beobachtungen. Wie viele beobachtbare Variablen ben√∂tigen Sie? √úberpr√ºfen Sie den Posteriori-Modus mithilfe des \texttt{mode\_check} Kommandos. Falls Sie Warnmeldungen aufgrund einer nicht positiv-definiten Hessematrix erhalten, verwenden Sie einen anderen Optimierungsalgorithmus oder ver√§ndern Sie ihre Anfangswerte.
\seti
\end{enumerate}
\end{frame}

\begin{frame}\frametitle{Aufgabe 5: Sch\"{a}tzung mit Bayesianischen Methoden}
  \begin{enumerate}[(a)]\conti
      \item Wenn Sie zufrieden sind mit dem Wert Ihres Posteriori-Modus, approximieren Sie die Posteriori-Verteilung mithilfe des Metropolis- Hastings-Algorithmus mit $3\times 5000$ Iterationen. Falls dies nicht zu der (ergodischen) Posteriori-Verteilung konvergiert, wiederholen Sie den Algorithmus ohne die vorherigen Ziehungen zu verwerfen.
  \item Wie steht es um die Robustheit ihres Ergebnisses bez√ºglich der Spezifikation ihrer Priori-Verteilungen? Wiederholen Sie die Sch√§tzung des Posteriori-Modus f√ºr verschiedene Priori-Verteilungen.
\seti\end{enumerate}
\end{frame}


\subsection{Inferenz, Prognose, Modellvergleich und Identifikation}
\begin{frame}\frametitle{Verfahren vollst\"{a}ndiger Information}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}\frametitle{Inferenz, Prognose, Modellvergleich und Identifikation}\framesubtitle{Eigenschaften der Posteriori-Verteilung}
\begin{itemize}
  \item Die Posteriori-Verteilung verkn√ºpft alle zur Verf√ºgung stehenden Daten √ºber $\mathbf{\mu}$: sowohl Informationen der Daten als auch derjenigen, bevor man die Daten beobachtet hat.
  \item Bayesianische Inferenz funktioniert f√ºr jeden Beobachtungszeitraum, hat zus√§tzlich aber auch folgende asymptotische Eigenschaften:
    \begin{enumerate}
      \item Die Priori-Verteilung wird bei zunehmenden Beobachtungenszeitraum irrelevant f√ºr die Bestimmung der Posteriori-Verteilung.
      \item Die Posteriori-Verteilung konvergiert zu einer degenerierten Verteilung um den wahren Wert.
      \item Die Posteriori-Verteilung ist approximativ normal-verteilt.
    \end{enumerate}
  \item Mithilfe der Posteriori-Verteilung lassen sich nun
  \begin{itemize}
  \item Bayesianische Konfidenzintervalle (credibility sets) aufstellen,
  \item Prognosen erstellen mithilfe der predictive-density: $\mathcal{L}(\mathbf{X_f}|\mathbf{X})= \int \mathcal{L}(\mathbf{X_f}|(\boldsymbol{\mu}|\mathbf{X}))d \boldsymbol{\mu} = \int \mathcal{L}(\mathbf{X_f}|\boldsymbol{\mu},\mathbf{X})\wp(\boldsymbol{\mu}|\mathbf{X})d\boldsymbol{\mu}$
  \item Modellvergleiche durchf√ºhren.
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}\frametitle{Inferenz, Prognose, Modellvergleich und Identifikation}\framesubtitle{Modellvergleiche}
  \begin{itemize}
    \item Modelle k√∂nnen sich in ihrer Priori-Verteilung, ihrer Likelihood oder ihren Parametern unterscheiden.
    \item Bayesianische Herangehensweise: Berechne die Wahrscheinlichkeit, dass Modell $i$ das wahre Modell ist, gegeben der Daten.
    \item O.B.d.A.: Angenommen es gibt $i=1,2$ Modelle $M_i$ mit jeweiliger Priori-Wahrscheinlichkeit $p_i=P(M_i)$, dass Modell $M_i$ das wahre Modell ist.
    \item Jedes Modell besitzt eine Menge von Parametern $\boldsymbol{\mu_i}$, einer Priori-Verteilung f√ºr diese $\wp_i(\boldsymbol{\mu_i})$ und einer Likelihood $\mathcal{L}_i(\mathbf{X}|\boldsymbol{\mu})$.
    \item Dann ist die Wahrscheinlichkeit, dass Modell 1 das wahre Modell ist, gegeben der Daten:
    \scriptsize\begin{align*}
      P(M_1|X) &= \frac{P(M_1)\mathcal{L}_1(\mathbf{X}|M_1)}{\mathcal{L}(\mathbf{X})} = \frac{p_1 \int \mathcal{L}_1(\mathbf{X},\mathbf{\boldsymbol{\mu_1}}|M_1)d \boldsymbol{\mu_1}}{\mathcal{L}(\mathbf{X})}\\
      &= \frac{p_1 \int \mathcal{L}_1(\mathbf{X}|\boldsymbol{\mu_1},M_1) \wp_1(\boldsymbol{\mu_1}|M_1) d \boldsymbol{\mu_1}}{\mathcal{L}(\mathbf{X})}\\
      \text{mit }& \mathcal{L}(\mathbf{X}) = p_1 \int \mathcal{L}_1(\mathbf{X}|\boldsymbol{\mu_1},M_1)\wp_1(\boldsymbol{\mu_1}|M_1)d\boldsymbol{\mu_1} + p_2 \int \mathcal{L}_2(\mathbf{X}|\boldsymbol{\mu_2},M_2)\wp_2(\boldsymbol{\mu_2}|M_2)d\boldsymbol{\mu_2}
    \end{align*}
  \end{itemize}
\end{frame}

\begin{frame}\frametitle{Inferenz, Prognose, Modellvergleich und Identifikation}\framesubtitle{Modellvergleiche}
  \begin{itemize}
      \item Der erwartete Wert der Likelihood unter Ber√ºcksichtigung der Priori-Verteilung ist die \emph{Marginal-Likelihood} f√ºr Modell i:
    \begin{align*}
      m_i(\mathbf{X}) = \int \mathcal{L}_i(\mathbf{X}|\boldsymbol{\mu_i},M_i)\wp_i(\boldsymbol{\mu_i}|M_i)d\boldsymbol{\mu_i}
    \end{align*}
    \item Daraus lassen sich nun die \emph{Posterior-Odds} berechnen:
    \begin{align*}
      PO_{12} = \frac{P(M_1|\mathbf{X})}{P(M_2|\mathbf{X})} = \underbrace{\frac{p_1}{p_2}}_{\text{Prior-Odds-Ratio}}\cdot \underbrace{\frac{m_1(\mathbf{X})}{m_2(\mathbf{X})}}_{Bayes-Faktor}
    \end{align*}
    \item Zusammen mit $P(M_1|\mathbf{X}) + P(M_2|\mathbf{X}) =1$ ergeben sich die \emph{Posterior-Model-Probabilities}:
    \begin{align*}
      P(M_1|\mathbf{X}) = \frac{PO_{12}}{1+PO_{12}}, \qquad P(M_2|\mathbf{X}) = 1-P(M_1|\mathbf{X}).
    \end{align*}
  \end{itemize}
\end{frame}

\begin{frame}\frametitle{Inferenz, Prognose, Modellvergleich und Identifikation}\framesubtitle{Modellvergleiche}
  \begin{itemize}
    \item Die \emph{Marginal Likelihood} misst die Qualit√§t eines Modells die Daten zu charakterisieren.
    \item Die \emph{Posterior-Odds} geben keinen Hinweis auf das wahre Modell, sie beschreiben lediglich, welches Modell im Vergleich zu anderen Modellen die h√∂chste bedingte Wahrscheinlichkeit besitzt.
    \item Ein gro√ües $PO_{12}>>1$ spricht daf√ºr, dass die Daten und die Priori-Verteilungen das Modell 1 bevorzugen.
    \item Guidelines von Jeffrey (1961):
    \begin{itemize}
      \item $1:1 - 3:1\quad~~$ sehr schwache Evidenz f√ºr Modell 1,
      \item $10:1 - 100:1~$ starke Evidenz f√ºr Modell 1,
      \item $> 100:1\qquad~~$ entscheidende Evidenz f√ºr Modell 1.
    \end{itemize}
    \item Die Implementation und Berechnung der Integrale geschieht mit numerischen MCMC- und Sampling-Methoden, sowie der Laplace- bzw. Harmonic-Mean-Approximation.
  \end{itemize}
\end{frame}


\begin{frame}\frametitle{Aufgabe 5: Sch\"{a}tzung mit Bayesianischen Methoden}
  \begin{enumerate}[(a)]\conti
  \item Benutzen Sie denselben Datensatz, um die Parameter eines fehlspezifizierten Modells zu sch√§tzen. Verwenden Sie hierzu das selbe Modell, jedoch entweder mit
      \begin{itemize}
      \item \textbf{einer Cobb-Douglas Produktionsfunktion $\Leftarrow$}
      \item oder einer separierbaren Nutzenfunktion
      \item oder einem Modell, indem der Haushalt unelastisch genau eine Einheit Arbeit anbietet.
      \end{itemize}\emph{\textbf{Hinweis}: Vergessen Sie nicht sowohl die Modellgleichungen als auch die steady-state Gleichungen entsprechend anzupassen.}
      \item Vergleichen Sie nun die Sch√§tzung der gemeinsamen Parameter sowie die marginalen Dichten der verschiedenen Modelle. Berechnen Sie auch die \emph{Posterior-Odds} bzw. die \emph{Posterior-Model-Probabilities}.

\end{enumerate}
\end{frame}


\begin{frame}\frametitle{Inferenz, Prognose, Modellvergleich und Identifikation}\framesubtitle{Identifikation}
  \begin{itemize}
    \item Betrachte zwei Parametervektoren $\boldsymbol{\mu_1}$ und $\boldsymbol{\mu_2}$ f√ºr die folgendes gilt:
    \begin{align*}
    \mathcal{L}(\mathbf{X}|\boldsymbol{\mu_1}) = \mathcal{L}(\mathbf{X}|\boldsymbol{\mu_2})
    \end{align*}
    \item Falls $\boldsymbol{\mu_1} = \boldsymbol{\mu_2}$ spricht man von Identifikation, falls dies jedoch f√ºr $\boldsymbol{\mu_1} \neq \boldsymbol{\mu_2}$  gilt, so wei√ü man nicht, welcher Parametervektor die Daten generiert hat.
    \item Spezialfall: $\mathcal{L}(\mathbf{X}|\boldsymbol{\mu_1},\boldsymbol{\mu_2}) = \mathcal{L}(\mathbf{X}|\boldsymbol{\mu_1})$.
    \begin{itemize}
    \item $\boldsymbol{\mu_2}$ ist durch die Daten nicht identifiziert.
    \item Was gilt f√ºr die Posteriori-Verteilung $\wp(\boldsymbol{\mu_2}|\mathbf{X})$?
    \scriptsize\begin{align*}
  \wp(\boldsymbol{\mu_2}|\mathbf{X}) &= \int \wp(\boldsymbol{\mu_1},\boldsymbol{\mu_2}|\mathbf{X}) d \boldsymbol{\mu_1}\\
  &=  \left[\int\mathcal{L}(\mathbf{X}|\boldsymbol{\mu_1},\boldsymbol{\mu_2})\wp(\boldsymbol{\mu_1})\wp(\boldsymbol{\mu_2}|\boldsymbol{\mu_1}) d \boldsymbol{\mu_1}\right] \cdot [\mathcal{L}(\mathbf{X})]^{-1}\\
  &=  \left[\int\mathcal{L}(\mathbf{X}|\boldsymbol{\mu_1})\wp(\boldsymbol{\mu_1})\wp(\boldsymbol{\mu_2}|\boldsymbol{\mu_1}) d \boldsymbol{\mu_1}\right] \cdot [\mathcal{L}(\mathbf{X})]^{-1}\\
  &= \int \wp(\boldsymbol{\mu_1}|X)\wp(\boldsymbol{\mu_2}|\boldsymbol{\mu_1})d \boldsymbol{\mu_1}
    \end{align*}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}\frametitle{Inferenz, Prognose, Modellvergleich und Identifikation}\framesubtitle{Identifikation}
\begin{itemize}
  \item Falls die Priori-Verteilung von $\boldsymbol{\mu_2}$ unabh√§ngig von $\boldsymbol{\mu_1}$ ist, d.h. $\wp (\boldsymbol{\mu_2}|\boldsymbol{\mu_1})=\wp(\boldsymbol{\mu_2})$, dann folgt $\wp(\boldsymbol{\mu_2}|\mathbf{X})=\wp(\boldsymbol{\mu_2})$. Beliefs √ºber $\boldsymbol{\mu_2}$ werden durch das Beobachten der Daten nicht modifiziert.
  \item Falls die Unabh√§ngigkeit der Priori-Verteilungen nicht gilt, so beeinflusst die Information der Daten die Beliefs √ºber $\boldsymbol{\mu_2}$ √ºber den Einfluss auf $\boldsymbol{\mu_1}$.
  \item Falls also eine Identifikation mithilfe der Daten nicht m√∂glich ist, ist jeglicher Unterscheid zwischen der Priori- und Posteriori-Verteilung auf die Priori-Verteilung zur√ºckzuf√ºhren.
  \item Praktisch muss man sich damit auseinander setzen, ob Parameter durch die Daten oder durch die Priori-Verteilungen identifiziert sind.
\end{itemize}
\end{frame}


\section{Diskussion}
\begin{frame}\frametitle{Verfahren vollst\"{a}ndiger Information}
  \tableofcontents[currentsection]
\end{frame}

\begin{frame}\frametitle{Diskussion}
  \begin{itemize}
       \item Restriktivere Annahmen als bei den Verfahren begrenzter Information: Spezifikation der Verteilung der Schocks, die sogenannte Likelihood.
    \item Vorteile einer \emph{Maximum-Likelihood}-Sch\"{a}tzung liegen in der vollen Charakterisierung des Daten generierenden Prozesses und der genaueren, konsistenten sowie effizienteren Sch\"{a}tzung der Parameter.
    \item \enquote{Dilemma of absurd parameter estimates}: Problem der ML-Sch\"{a}tzung, aufgrund fehlerhaften Verteilungsannahmen, Problemen im Optimierungsalgorithmus oder bei nicht separat identifizierbaren Parametern.
    \item Auch Transformationen, obere und untere Grenzen, etc. k√∂nnen nur bedingt helfen, wenn die Likelihood-Funktion sehr flach verl√§uft.
  \end{itemize}
  \begin{block}{Grundproblem}  F\"{u}r einen mathematischen Ausdruck mit vielen Bedingungen und Parametern, aber nur einem begrenzten Beobachtungszeitraum, k√∂nnen verschiedene Parameterkonstellationen existieren, die zum selben Ergebnis und somit auch zu einem \"{a}hnlichen Datensatz f\"{u}hren.\end{block}

\end{frame}

\begin{frame}\frametitle{Diskussion}
  \begin{itemize}
    \item An diesem Punkt setzen bayesianische Methoden an und bilden eine Br\"{u}cke zwischen der Kalibrierung und dem \emph{ML-Prinzip}.
    \item Durch das Ber\"{u}cksichtigen von Priors lassen sich auch nicht modellierte Informationen im Modell verarbeiten.
    \item \enquote{Dilemma of absurd parameter estimates}: Auch mit bayesianischen Mitteln werden diese Parameter nicht gesch\"{a}tzt (die Priori-Verteilung unterscheidet sich kaum von der Posteriori-Verteilung), sondern durch eine Belegung mit Wahrscheinlichkeit festgelegt.
    \item[$\Rightarrow$] Durch die Wahl von Priors lassen sich diese absurd erscheinenden Werte ausschlie{\ss}en.
    \item Trotzdem bleibt die Frage nach Robustheit und der Identifizierbarkeit der Parameter kritisch.
  \end{itemize}
\end{frame}

\begin{frame}\frametitle{Diskussion}

\begin{block}{An und Schorfheide (2006, S.124)}
Once one acknowledges that the DSGE model provides merely an approximation to
the law of motion of the time series (\dots), then it seems reasonable to
assume that there need not exist a single parameter vector (\dots), that
delivers, say, the \enquote{true} intertemporal substitution elasticity or
price adjustment costs and, simultaneously, the most precise impulse
responses to a technology or monetary policy shock. Each estimation method is
associated with a particular measure of discrepancy between the
\enquote{true} law of motion and the class of approximating models.
\end{block}
\end{frame}


\end{document}







